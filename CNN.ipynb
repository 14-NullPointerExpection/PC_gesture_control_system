{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n",
      "[2, 0, 2, 3, 3, 2, 1, 2, 1, 0, 3, 2, 2, 3, 1, 2, 2, 3, 2, 3, 2, 2, 2, 0, 1, 2, 3, 3, 0, 0, 2, 0, 3, 2, 0, 2, 2, 2, 3, 2, 2, 0, 0, 2, 2, 0, 0, 0, 1, 3, 3, 3, 1, 3, 3, 3, 3, 3, 1, 2, 3, 3, 0, 0, 1, 1, 2, 2, 1, 0, 1, 0, 2, 1, 1, 0, 1, 0, 2, 0, 3, 0, 3, 2, 1, 0, 3, 2, 3, 2, 2, 3, 2, 2, 0, 2, 2, 2, 0, 0, 3, 1, 2, 2, 0, 0, 1, 2, 0, 3, 3, 1, 1, 2, 3, 2, 1, 3, 3, 1, 0, 1, 3, 0, 2, 1, 1, 2, 0, 3, 2, 3, 3, 0, 3, 1, 3, 0, 1, 1, 1, 0, 0, 3, 1, 0, 0, 3, 2, 0, 3, 0, 2, 1, 1, 1, 3, 3, 3, 3, 0, 3, 1, 1, 0, 3, 0, 0, 0, 1, 0, 2, 2, 1, 2, 1, 2, 3, 1, 2, 0, 1, 0, 0, 1, 3, 2, 3, 1, 0, 0, 0, 3, 0, 2, 2, 0, 0, 1, 2, 3, 0, 0, 1, 0, 3, 0, 3, 1, 1, 3, 0, 0, 2, 3, 1, 1, 2, 1, 0, 2, 0, 0, 1, 0, 3, 1, 3, 2, 3, 2, 0, 2, 1, 0, 0, 2, 0, 0, 3, 1, 0, 3, 3, 1, 3, 1, 3, 1, 2, 0, 0, 2, 0, 2, 1, 3, 3, 1, 2, 0, 3, 0, 2, 0, 2, 3, 1, 3, 3, 1, 0, 1, 3, 2, 2, 1, 3, 2, 3, 2, 0, 3, 2, 1, 1, 1, 0, 1, 1, 3, 3, 2, 3, 1, 1, 0, 0, 1, 2, 1, 0, 3, 2, 1, 3, 0, 3, 2, 3, 0, 2, 2, 2, 1, 3, 3, 3, 3, 2, 2, 3, 1, 3, 3, 1, 1, 0, 2, 1, 1, 0, 2, 3, 2, 3, 1, 2, 3, 2, 1, 0, 1, 1, 0, 3, 2, 1, 0, 1, 3, 1, 2, 1, 3, 1, 3, 3, 1, 3, 3, 3, 0, 2, 2, 0, 0, 0, 2, 2, 0, 1, 2, 1, 1, 1, 3, 0, 0, 1, 2, 1, 2, 0, 1, 1, 0, 2, 0, 1, 1, 2, 2, 0, 2, 3, 0, 1, 1, 1]\n",
      "[3, 0, 2, 1, 1, 2, 3, 1, 2, 3, 3, 0, 0, 0, 2, 0, 2, 1, 2, 3, 1, 2, 2, 2, 1, 0, 2, 1, 0, 0, 1, 0, 3, 0, 2, 2, 1, 0, 3, 1, 0, 0, 3, 1, 2, 0, 3, 2, 2, 1, 0, 3, 0, 0, 1, 0, 3, 3, 0, 3, 0, 1, 3, 1, 3, 2, 0, 0, 2, 2, 0, 0, 3, 1]\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 100, 100, 32)      2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 50, 50, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 50, 50, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 25, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 25, 25, 64)        36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 40000)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               20480512  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 20,604,548\n",
      "Trainable params: 20,604,548\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/35\n",
      "25/25 [==============================] - 3s 112ms/step - loss: 1.3905 - accuracy: 0.2525\n",
      "Epoch 2/35\n",
      "25/25 [==============================] - 3s 123ms/step - loss: 1.3818 - accuracy: 0.2750 - val_loss: 1.3852 - val_accuracy: 0.2432\n",
      "Epoch 3/35\n",
      "25/25 [==============================] - 3s 110ms/step - loss: 1.3774 - accuracy: 0.3150\n",
      "Epoch 4/35\n",
      "25/25 [==============================] - 3s 119ms/step - loss: 1.3709 - accuracy: 0.3925 - val_loss: 1.3730 - val_accuracy: 0.3649\n",
      "Epoch 5/35\n",
      "25/25 [==============================] - 3s 112ms/step - loss: 1.3666 - accuracy: 0.4075\n",
      "Epoch 6/35\n",
      "25/25 [==============================] - 3s 119ms/step - loss: 1.3602 - accuracy: 0.4475 - val_loss: 1.3596 - val_accuracy: 0.5270\n",
      "Epoch 7/35\n",
      "25/25 [==============================] - 3s 113ms/step - loss: 1.3557 - accuracy: 0.4725\n",
      "Epoch 8/35\n",
      "25/25 [==============================] - 3s 119ms/step - loss: 1.3503 - accuracy: 0.4975 - val_loss: 1.3448 - val_accuracy: 0.6351\n",
      "Epoch 9/35\n",
      "25/25 [==============================] - 3s 113ms/step - loss: 1.3445 - accuracy: 0.5275\n",
      "Epoch 10/35\n",
      "25/25 [==============================] - 3s 120ms/step - loss: 1.3290 - accuracy: 0.6325 - val_loss: 1.3266 - val_accuracy: 0.6892\n",
      "Epoch 11/35\n",
      "25/25 [==============================] - 3s 113ms/step - loss: 1.3278 - accuracy: 0.5525\n",
      "Epoch 12/35\n",
      "25/25 [==============================] - 3s 120ms/step - loss: 1.3097 - accuracy: 0.6550 - val_loss: 1.3039 - val_accuracy: 0.7297\n",
      "Epoch 13/35\n",
      "25/25 [==============================] - 3s 111ms/step - loss: 1.3039 - accuracy: 0.6575\n",
      "Epoch 14/35\n",
      "25/25 [==============================] - 3s 118ms/step - loss: 1.2903 - accuracy: 0.6825 - val_loss: 1.2752 - val_accuracy: 0.7162\n",
      "Epoch 15/35\n",
      "25/25 [==============================] - 3s 111ms/step - loss: 1.2784 - accuracy: 0.6700\n",
      "Epoch 16/35\n",
      "25/25 [==============================] - 3s 119ms/step - loss: 1.2608 - accuracy: 0.6650 - val_loss: 1.2368 - val_accuracy: 0.7432\n",
      "Epoch 17/35\n",
      "25/25 [==============================] - 3s 112ms/step - loss: 1.2373 - accuracy: 0.6775\n",
      "Epoch 18/35\n",
      "25/25 [==============================] - 3s 118ms/step - loss: 1.2134 - accuracy: 0.6950 - val_loss: 1.1850 - val_accuracy: 0.7432\n",
      "Epoch 19/35\n",
      "25/25 [==============================] - 3s 111ms/step - loss: 1.1896 - accuracy: 0.6975\n",
      "Epoch 20/35\n",
      "25/25 [==============================] - 3s 118ms/step - loss: 1.1579 - accuracy: 0.7450 - val_loss: 1.1149 - val_accuracy: 0.7432\n",
      "Epoch 21/35\n",
      "25/25 [==============================] - 3s 111ms/step - loss: 1.1192 - accuracy: 0.7200\n",
      "Epoch 22/35\n",
      "25/25 [==============================] - 3s 118ms/step - loss: 1.0817 - accuracy: 0.7400 - val_loss: 1.0203 - val_accuracy: 0.7568\n",
      "Epoch 23/35\n",
      "25/25 [==============================] - 3s 111ms/step - loss: 1.0251 - accuracy: 0.7700\n",
      "Epoch 24/35\n",
      "25/25 [==============================] - 3s 119ms/step - loss: 0.9535 - accuracy: 0.7725 - val_loss: 0.8962 - val_accuracy: 0.7703\n",
      "Epoch 25/35\n",
      "25/25 [==============================] - 3s 111ms/step - loss: 0.9079 - accuracy: 0.8025\n",
      "Epoch 26/35\n",
      "25/25 [==============================] - 3s 117ms/step - loss: 0.8484 - accuracy: 0.7900 - val_loss: 0.7607 - val_accuracy: 0.8378\n",
      "Epoch 27/35\n",
      "25/25 [==============================] - 3s 111ms/step - loss: 0.7790 - accuracy: 0.8075\n",
      "Epoch 28/35\n",
      "25/25 [==============================] - 3s 118ms/step - loss: 0.7085 - accuracy: 0.8400 - val_loss: 0.6283 - val_accuracy: 0.8784\n",
      "Epoch 29/35\n",
      "25/25 [==============================] - 3s 111ms/step - loss: 0.6396 - accuracy: 0.8650\n",
      "Epoch 30/35\n",
      "25/25 [==============================] - 3s 119ms/step - loss: 0.5933 - accuracy: 0.8725 - val_loss: 0.5003 - val_accuracy: 0.8919\n",
      "Epoch 31/35\n",
      "25/25 [==============================] - 3s 112ms/step - loss: 0.5230 - accuracy: 0.8925\n",
      "Epoch 32/35\n",
      "25/25 [==============================] - 3s 120ms/step - loss: 0.4867 - accuracy: 0.8775 - val_loss: 0.3854 - val_accuracy: 0.9054\n",
      "Epoch 33/35\n",
      "25/25 [==============================] - 3s 112ms/step - loss: 0.4532 - accuracy: 0.9000\n",
      "Epoch 34/35\n",
      "25/25 [==============================] - 3s 119ms/step - loss: 0.3957 - accuracy: 0.8975 - val_loss: 0.2897 - val_accuracy: 0.9730\n",
      "Epoch 35/35\n",
      "25/25 [==============================] - 3s 113ms/step - loss: 0.3369 - accuracy: 0.9150\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.2573 - accuracy: 0.9865\n",
      "WARNING:tensorflow:From d:\\Coding\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From d:\\Coding\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\kjhjk\\Desktop\\data\\model\\assets\n",
      "保存模型成功\n",
      "--------------------------------------------------\n",
      "Frozen model layers: \n",
      "x\n",
      "sequential/conv2d/Conv2D/ReadVariableOp/resource\n",
      "sequential/conv2d/Conv2D/ReadVariableOp\n",
      "sequential/conv2d/Conv2D\n",
      "sequential/conv2d/BiasAdd/ReadVariableOp/resource\n",
      "sequential/conv2d/BiasAdd/ReadVariableOp\n",
      "sequential/conv2d/BiasAdd\n",
      "sequential/conv2d/Relu\n",
      "sequential/max_pooling2d/MaxPool\n",
      "sequential/conv2d_1/Conv2D/ReadVariableOp/resource\n",
      "sequential/conv2d_1/Conv2D/ReadVariableOp\n",
      "sequential/conv2d_1/Conv2D\n",
      "sequential/conv2d_1/BiasAdd/ReadVariableOp/resource\n",
      "sequential/conv2d_1/BiasAdd/ReadVariableOp\n",
      "sequential/conv2d_1/BiasAdd\n",
      "sequential/conv2d_1/Relu\n",
      "sequential/max_pooling2d_1/MaxPool\n",
      "sequential/conv2d_2/Conv2D/ReadVariableOp/resource\n",
      "sequential/conv2d_2/Conv2D/ReadVariableOp\n",
      "sequential/conv2d_2/Conv2D\n",
      "sequential/conv2d_2/BiasAdd/ReadVariableOp/resource\n",
      "sequential/conv2d_2/BiasAdd/ReadVariableOp\n",
      "sequential/conv2d_2/BiasAdd\n",
      "sequential/conv2d_2/Relu\n",
      "sequential/flatten/Const\n",
      "sequential/flatten/Reshape\n",
      "sequential/dense/MatMul/ReadVariableOp/resource\n",
      "sequential/dense/MatMul/ReadVariableOp\n",
      "sequential/dense/MatMul\n",
      "sequential/dense/BiasAdd/ReadVariableOp/resource\n",
      "sequential/dense/BiasAdd/ReadVariableOp\n",
      "sequential/dense/BiasAdd\n",
      "sequential/dense/Relu\n",
      "sequential/dropout/Identity\n",
      "sequential/dense_1/MatMul/ReadVariableOp/resource\n",
      "sequential/dense_1/MatMul/ReadVariableOp\n",
      "sequential/dense_1/MatMul\n",
      "sequential/dense_1/BiasAdd/ReadVariableOp/resource\n",
      "sequential/dense_1/BiasAdd/ReadVariableOp\n",
      "sequential/dense_1/BiasAdd\n",
      "sequential/dense_1/Relu\n",
      "sequential/dense_2/MatMul/ReadVariableOp/resource\n",
      "sequential/dense_2/MatMul/ReadVariableOp\n",
      "sequential/dense_2/MatMul\n",
      "sequential/dense_2/BiasAdd/ReadVariableOp/resource\n",
      "sequential/dense_2/BiasAdd/ReadVariableOp\n",
      "sequential/dense_2/BiasAdd\n",
      "Identity\n",
      "--------------------------------------------------\n",
      "Frozen model inputs: \n",
      "[<tf.Tensor 'x:0' shape=(None, 100, 100, 3) dtype=float32>]\n",
      "Frozen model outputs: \n",
      "[<tf.Tensor 'Identity:0' shape=(None, 4) dtype=float32>]\n",
      "模型转换完成，训练结束\n"
     ]
    }
   ],
   "source": [
    "# from tkinter import image_names\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets,layers,optimizers,Sequential,metrics\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "\n",
    "\n",
    "\n",
    "def read_data(path):\n",
    "    path_root = pathlib.Path(path)\n",
    "    # print(path_root)\n",
    "    # for item in path_root.iterdir():\n",
    "    #     print(item)\n",
    "    image_paths = list(path_root.glob('*/*'))\n",
    "    #print(image_paths)\n",
    "    image_paths = [str(path) for path in image_paths]\n",
    "    #print(image_paths)\n",
    "    random.shuffle(image_paths)\n",
    "    image_count = len(image_paths)\n",
    "    # print(image_count)\n",
    "    # print(image_paths[:10])\n",
    "\n",
    "    label_names = sorted(item.name for item in path_root.glob('*/') if item.is_dir())\n",
    "    #print(label_names)\n",
    "    label_name_index = dict((name, index) for index, name in enumerate(label_names))\n",
    "    #print(label_name_index)\n",
    "    image_labels = [label_name_index[pathlib.Path(path).parent.name] for path in image_paths]\n",
    "    print(image_labels)\n",
    "    #print(\"First 10 labels indices: \", image_labels[:10])\n",
    "    return image_paths,image_labels,image_count\n",
    "\n",
    "\n",
    "def binaryMask(frame,x0,y0,width,height):\n",
    "    cv2.rectangle(frame,(x0,y0),(x0+width,y0+height),(0,255,0))\n",
    "    roi = frame[y0:y0+height,x0:x0+width]\n",
    "    #cv2.imshow(\"roi\",roi)#读取roi文件\n",
    "    res = skinMask(roi)\n",
    "    #cv2.imshow(\"res\",res)\n",
    "    return res\n",
    "\n",
    "\n",
    "def skinMask(roi):\n",
    "    #rgb = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)  # 转换到RGB空间\n",
    "    CrCb=cv2.cvtColor(roi, COLOR_BGR2YCrCb)\n",
    "    (Y,Cr,Cb) = cv2.split(CrCb)  # 获取图像每个像素点的RGB的值，即将一个二维矩阵拆成三个二维矩阵\n",
    "    skin = np.zeros(Cr.shape, dtype=np.uint8)  # 掩膜\n",
    "    (x, y) = Cb.shape  # 获取图像的像素点的坐标范围\n",
    "    for i in range(0, x):\n",
    "        for j in range(0, y):\n",
    "            # 判断条件，不在肤色范围内则将掩膜设为黑色，即255\n",
    "            # if (abs(R[i][j] - G[i][j]) > 15) and (R[i][j] > G[i][j]) and (R[i][j] > B[i][j]):\n",
    "            #     if (R[i][j] > 95) and (G[i][j] > 40) and (B[i][j] > 20) \\\n",
    "            #             and (max(R[i][j], G[i][j], B[i][j]) - min(R[i][j], G[i][j], B[i][j]) > 15):\n",
    "            #         skin[i][j] = 255\n",
    "            #     elif (R[i][j] > 220) and (G[i][j] > 210) and (B[i][j] > 170):\n",
    "            #         skin[i][j] = 255\n",
    "            if (Cr[i][j] > 133) and (Cr[i][j] < 170) and (Cb[i][j] > 77) and (Cb[i][j] < 127):\n",
    "                skin[i][j] = 255\n",
    "            else:\n",
    "                skin[i][j] = 0\n",
    "    res = cv2.bitwise_and(roi, roi, mask=skin)  # 图像与运算\n",
    "    return res\n",
    "\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [100, 100])\n",
    "    image /= 255.0  # normalize to [0,1] range\n",
    "    # image = tf.reshape(image,[100*100*3])\n",
    "    return image\n",
    "\n",
    "def load_and_preprocess_image(path,label):\n",
    "    image = tf.io.read_file(path)\n",
    "    return preprocess_image(image),label\n",
    "\n",
    "def creat_dataset(image_paths,image_labels,bitch_size):\n",
    "    db = tf.data.Dataset.from_tensor_slices((image_paths, image_labels))\n",
    "    #print(\"db:\")\n",
    "    \n",
    "    dataset = db.map(load_and_preprocess_image).batch(bitch_size)  \n",
    "    # for i in dataset:\n",
    "    #     print(i)  \n",
    "    return dataset\n",
    "\n",
    "\n",
    "def train_model(train_data,test_data):\n",
    "    #构建模型\n",
    "    network = keras.Sequential([\n",
    "            keras.layers.Conv2D(32,kernel_size=[5,5],padding=\"same\",activation=tf.nn.relu),\n",
    "            keras.layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same'),\n",
    "            keras.layers.Conv2D(64,kernel_size=[3,3],padding=\"same\",activation=tf.nn.relu),\n",
    "            keras.layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same'),\n",
    "            keras.layers.Conv2D(64,kernel_size=[3,3],padding=\"same\",activation=tf.nn.relu),\n",
    "            keras.layers.Flatten(),\n",
    "            keras.layers.Dense(512,activation='relu'),\n",
    "            keras.layers.Dropout(0.5),\n",
    "            keras.layers.Dense(128,activation='relu'),\n",
    "            keras.layers.Dense(4)])\n",
    "    network.build(input_shape=(None,100,100,3))\n",
    "    network.summary()\n",
    "\n",
    "    network.compile(optimizer=optimizers.SGD(lr=0.001),\n",
    "            loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            metrics=['accuracy']\n",
    "    )\n",
    "    #模型训练\n",
    "    network.fit(train_data, epochs = 35,validation_data=test_data,validation_freq=2)  \n",
    "    network.evaluate(test_data)\n",
    "\n",
    "    tf.saved_model.save(network,'./model')\n",
    "    print(\"保存模型成功\")\n",
    "\n",
    "\n",
    "\n",
    "    # Convert Keras model to ConcreteFunction\n",
    "    full_model = tf.function(lambda x: network(x))\n",
    "    full_model = full_model.get_concrete_function(\n",
    "        tf.TensorSpec(network.inputs[0].shape, network.inputs[0].dtype))\n",
    "\n",
    "    # Get frozen ConcreteFunction\n",
    "    frozen_func = convert_variables_to_constants_v2(full_model)\n",
    "    frozen_func.graph.as_graph_def()\n",
    "\n",
    "    layers = [op.name for op in frozen_func.graph.get_operations()]\n",
    "    print(\"-\" * 50)\n",
    "    print(\"Frozen model layers: \")\n",
    "    for layer in layers:\n",
    "        print(layer)\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "    print(\"Frozen model inputs: \")\n",
    "    print(frozen_func.inputs)\n",
    "    print(\"Frozen model outputs: \")\n",
    "    print(frozen_func.outputs)                                                                                               \n",
    "\n",
    "    # Save frozen graph from frozen ConcreteFunction to hard drive\n",
    "    tf.io.write_graph(graph_or_graph_def=frozen_func.graph,\n",
    "            logdir=\"./frozen_model\",\n",
    "            name=\"frozen_graph.pb\",\n",
    "            as_text=False)\n",
    "    print(\"模型转换完成，训练结束\")\n",
    "\n",
    "\n",
    "if  __name__ == \"__main__\":\n",
    "    print(tf.__version__)\n",
    "    train_path = 'F:\\\\dataSet\\\\dataSetPro'\n",
    "    test_path = 'F:\\\\dataSet\\\\testdata' \n",
    "    image_paths,image_labels,_ = read_data(train_path)\n",
    "    train_data = creat_dataset(image_paths,image_labels,16)\n",
    "    image_paths,image_labels,_ = read_data(test_path)\n",
    "    test_data = creat_dataset(image_paths,image_labels,16)\n",
    "    train_model(train_data,test_data)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tf.compat.v1.enable_eager_execution()\n",
    "[9, 9, 2, 1, 2, 2, 7, 8, 4, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('work')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "029cb186bce3497bb06af8585b33248019023d24a8c601eb551013c6eafaaf9c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}